<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SAM2-Lite: Real-Time Video Segmentation</title>
    <meta name="description"
        content="SAM2-Lite: Bringing Real-Time Video Segmentation to Edge Devices Through Memory-Aware Knowledge Distillation.">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;800&display=swap" rel="stylesheet">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <!-- Styles -->
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div class="container">
        <header class="hero-section">
            <h1 class="paper-title">SAM2-Lite: Bringing Real-Time Video Segmentation to Edge Devices Through
                Memory-Aware Knowledge Distillation</h1>

            <div class="authors-list">
                <div class="author-block">
                    <span class="author-name">Roshan Pandey</span>
                    <span class="author-affiliation">Department of Electrical and Computer Engineering, Tribhuvan
                        University, Kathmandu, Nepal</span>
                </div>
            </div>

            <div class="link-buttons">
                <a href="SAM-2 lite.pdf.pdf" class="btn btn-primary">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                </a>
                <a href="https://github.com/Roshan20222" class="btn btn-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                </a>
                <a href="#citation" class="btn btn-secondary">
                    <span class="icon"><i class="fas fa-quote-right"></i></span>
                    <span>BibTeX</span>
                </a>
            </div>
        </header>

        <section class="section abstract-section">
            <h2 class="section-title">Abstract</h2>
            <div class="abstract-content">
                <p>Getting state-of-the-art video segmentation models to run on edge devices like smartphones and drones
                    remains a fundamental challenge in computer vision. While models like SAM2 deliver impressive
                    results, they require powerful GPUs and consume substantial energy, making them impractical for
                    resource-constrained devices. We present <strong>SAM2-Lite</strong>, a family of lightweight video
                    segmentation models designed specifically for real-time inference on edge hardware through
                    memory-aware knowledge distillation.</p>
                <p>Our approach is built on three key innovations. First, we introduce memory-aware distillation that
                    teaches the student model not just to match the teacher's outputs, but to replicate its temporal
                    reasoning by matching attention distributions and memory readouts. Second, we develop a learned
                    memory pruning mechanism that intelligently selects which frame features to retain within strict
                    device memory budgets. Third, we implement an adaptive inference system that dynamically adjusts
                    resolution and memory usage based on real-time device performance.</p>
                <p>Trained on YouTube-VOS, DAVIS, and other video datasets, SAM2-Lite achieves <strong>83.1% J&F
                        score</strong> on DAVIS 2017 (96% of SAM2's performance) while operating <strong>6.5×
                        faster</strong> with <strong>48× fewer parameters</strong>. On NVIDIA Jetson edge devices, it
                    processes frames in 20-35 milliseconds and consumes less than 1.3 watt-hours of energy for a
                    10-minute video, enabling hours of continuous operation on battery power.</p>
            </div>
        </section>

        <section class="section teaser-section">
            <div class="teaser-image-container">
                <img src="graphical_abstract_svg.svg" alt="SAM2-Lite Architecture Overview" class="teaser-image">
            </div>
            <p class="caption"><strong>Figure 1: SAM2-Lite Overview.</strong> Our architecture enables real-time video
                segmentation on edge devices by efficiently managing memory and computational resources while
                maintaining high accuracy.</p>
        </section>

        <section class="section results-section">
            <h2 class="section-title">Key Results</h2>
            <div class="results-grid">
                <div class="result-card">
                    <img src="drift_analysis_figure.svg" alt="Drift Analysis">
                    <p class="caption">Drift Analysis</p>
                </div>
                <div class="result-card">
                    <img src="energy_pareto_figure.svg" alt="Energy vs Accuracy">
                    <p class="caption">Energy-Accuracy Pareto Frontier</p>
                </div>
                <div class="result-card">
                    <img src="memory_analysis_figure.svg" alt="Memory Usage Analysis">
                    <p class="caption">Memory Usage Analysis</p>
                </div>
                <div class="result-card">
                    <img src="qualitative_results_figure.svg" alt="Qualitative Results">
                    <p class="caption">Qualitative Comparison</p>
                </div>
            </div>
        </section>

        <section class="section citation-section" id="citation">
            <h2 class="section-title">Citation</h2>
            <div class="citation-block">
                <pre><code>@article{pandey2024sam2lite,
  title={SAM2-Lite: Bringing Real-Time Video Segmentation to Edge Devices Through Memory-Aware Knowledge Distillation},
  author={Pandey, Roshan},
  journal={arXiv preprint},
  year={2025}
}</code></pre>
            </div>
        </section>

        <footer class="footer">
            <p>&copy; 2025 Roshan Pandey. Released under the MIT License.</p>
            <p>Website template inspired by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.</p>
        </footer>
    </div>
    <script src="script.js"></script>
</body>

</html>